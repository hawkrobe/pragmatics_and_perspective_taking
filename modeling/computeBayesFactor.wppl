// webppl noisyContextRSA.wppl --require ./refModule/ -- --model occlusionSensitivity
// webppl noisyContextRSA.wppl --require ./refModule/ -- --model egocentric

var data = refModule.readCSV('./input/bdaInput.csv');
var possibleUtterances = ['shape', 'color', 'texture',
			  'texture_color', 'color_shape', 'texture_shape',
			  'texture_color_shape'];

// hand-coded to match stimulus set used in experiment
var possibleObjects = Categorical({
  vs: ['texture_color_shape', 'otherTexture_color_shape', 'texture_otherColor_shape',
       'otherTexture_otherColor_shape',
       'texture_color_otherShape',
       'texture_otherColor_otherShape',
       'otherTexture_color_otherShape',
       'otherTexture_otherColor_otherShape'],
  ps: [1/64, 3/64, 3/64, 
       9/64,
       3/64,
       9/64,
       9/64,
       27/64]
});

//var possibleObjects = Categorical({vs: ['texture_otherColor_shape', 'otherTexture_otherColor_otherShape'], ps: [1/10, 9/10]})

var contexts = {
  'diff_shape' : ['texture_color_shape', 'otherTexture_otherColor_otherShape',
		  //'otherTexture_otherColor_otherShape'],
//		  'otherTexture_color_otherShape'
		  //'texture_otherColor_otherShape' 
		 ],
  'shape_only' : ['texture_color_shape', 'otherTexture_otherColor_shape',
		  //'otherTexture_otherColor_otherShape'],
//		  'otherTexture_color_otherShape'
//		  'texture_otherColor_otherShape'//, 
		 ],
  'color_shape' : ['texture_color_shape', 'otherTexture_color_shape',
		   //'otherTexture_otherColor_otherShape'],
		   //'texture_otherColor_otherShape',
		   //'otherTexture_color_otherShape'
		  ],
  'texture_shape' : ['texture_color_shape', 'texture_otherColor_shape',
		     //'otherTexture_otherColor_otherShape']
		     //'texture_otherColor_otherShape'
		     //'otherTexture_color_otherShape'
		     ]
};

// Utterance is true if all properties mentioned are properties of the object
var uttFitness = function(utt, object) {
  var descriptors = utt.split('_');
  var objProperties = object.split('_');
  var matches = _.every(map(function(descriptor) {
    return _.includes(objProperties, descriptor);
  }, descriptors));
  return matches ? 0 : -100;
};

var uttCost = function(utt, params) {
  var descriptors = utt.split('_');
  return sum(map(function(descriptor) {
    return descriptor == 'null' ? 0 : params[descriptor + 'Cost'];
  }, descriptors));
};

var L0 = cache(function(utt, perceivedContext) {
  return Infer({method: 'enumerate'}, function() {
    var object = uniformDraw(perceivedContext);
    factor(uttFitness(utt, object));
    return object;
  });
});

var occSensitiveUtility = function(target, utt, knownContext, params) {
  var hidden = params.hidden == 'yes';
  return expectation(possibleObjects, function(obj) {
    var possibleListenerView = hidden ? knownContext.concat(obj) : knownContext;
    return (L0(utt, possibleListenerView).score(target) - uttCost(utt,params));
  });
};

var basicUtility = function(target, utt, knownContext, params) {
  return (L0(utt, knownContext).score(target) - uttCost(utt, params));
};

// if occlusions, speaker has uncertainty over what's behind occluded square
var S = cache(function(target, knownContext, params) {
  return Infer({method: 'enumerate'}, function() {
    var utt = uniformDraw(possibleUtterances);
    var utility = (params.model == 'occlusionSensitivity' ?
		   occSensitiveUtility(target, utt, knownContext, params) :
		   basicUtility(target, utt, knownContext, params));
    factor(params.alpha * utility);
    return utt;
  });
});

var getResponse = cache(function(trialInfo) {
  var responses = map(function(attribute) {
    return trialInfo[attribute] == 'TRUE' ? attribute : '';
  }, ['texture', 'color', 'shape']);
  return filter(function(v) {return v != '';}, responses).join('_');
});

var getExpectedLength = function(condition, params) {
  return expectation(Infer({method: 'enumerate'}, function() {
    var additionalDistractor = (flip() ?
				'texture_otherColor_otherShape' :
				'otherTexture_color_otherShape');
    var knownContext = contexts[condition.distractorType].concat(additionalDistractor);
    var dist = S('texture_color_shape', knownContext, extend({}, params, {hidden: condition.hidden}));
    return sample(dist).split('_').length;
  }));
};		    

var bda = function() {
  var model = uniformDraw(['occlusionSensitivity', 'basic']);
  var alpha = uniformDraw(_.range(1, 27, 0.5));
  console.log('alpha: ' + alpha);
  var textureCost = Math.exp(uniformDraw(_.range(-10, -1, 1)));
  console.log('textureCost: ' + textureCost);
  var params = {
    model,alpha, textureCost,
    colorCost: Math.exp(uniformDraw(_.range(-10, -1, 1))),
    shapeCost: Math.exp(uniformDraw(_.range(-10, -1, 1)))
  };
  //var model = flip(params.modelPref) ? 'occlusionSensitivity' : 'basic';
  var score = sum(mapData({data: data}, function(datum) {
    var knownContext = contexts[datum.distractorType];
    var modelPrediction = S('texture_color_shape',
			    knownContext,
			    _.extend({}, params, {hidden: datum.hidden}));
    var response = getResponse(datum);
    return modelPrediction.score(response);
  }));
  factor(score);
  
  return params.model;
};

var outputERP = Infer({method: 'enumerate', model: bda});
console.log(outputERP.score('basic'));
console.log(outputERP.score('occlusionSensitivity'));
refModule.bayesianErpWriter(outputERP, "./bdaOutput/enumerate");

// console.log(S('texture_color_shape', {'context' : 'close', 'hidden' : 'yes'},
// 	      {model: 'occlusionSensitivity', alpha: 1, textureCost: 0, colorCost: 0, shapeCost: 0}))

// console.log(S('texture_color_shape', {'context' : 'close', 'hidden' : 'yes'},
// 	      {model: 'basic', alpha: 1, textureCost: 0, colorCost: 0, shapeCost: 0}))
